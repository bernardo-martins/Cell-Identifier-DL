Attention:
- Do not edit this file in text editors like Word. Use a plain text editor only. If in doubt you can use Spyder as a text editor.
- Do not change the structure of this file. Just fill in your answers in the places provided (After the R#: tag).
- You can add lines in the spaces for your answers but your answers should be brief and straight to the point.

Atenção:
- Não edite este ficheiro em programas como Word e afins. Use exclusivamente um editor de texto simples. Em caso de dúvida, use o editor do Spyder.
- Não altere a estrutura deste ficheiro. Preencha as respostas apenas nos espaços respectivos (a seguir à tag R#:)
- Pode adicionar linhas no espaço para as respostas mas as respostas devem ser sucintas e directas.

Linking images and reports/Incluir imagens e relatórios
- You can link a .png or .html file in your answers by typing the name of the file in a separate line. The file must be in the same folder as this TP1.txt file. See the examples below:
- Pode ligar às respostas um ficheiro .png ou .html escrevendo o nome do ficheiro numa linha separada. O ficheiro tem de estar presente na mesma pasta em que está este ficheiro TP1.txt. Por exemplo:

exemplo.png
exemplo.html

PERGUNTAS/QUESTIONS:

Q1: Explain the architecture of your best model for the multiclass classification problem, including a description and justification of the output activation and loss functions. Also justify your choice of layers and activation functions for the hidden layers.
Q1; Explique a arquitectura do seu melhor modelo para o problema de classificação de multi-classe, incluindo uma descrição e justificação das funções de activação à saída da rede e função de custo. Justifique também a sua escolha de camadas e de funções de activação para as camadas escondidas.
R1: Para o nosso modelo escolhemos uma arquitetura simples, construída a partir do exemplo da aula. Na primeira camada, começamos por agregar 3 camadas de 2 convoluções. A primeira camada serve para extrair as features mais gerais e mais simples, enquanto que as restantes duas camadas vão especializando o conhecimento da rede. De modo a aumentar a especificidade das features que estamos a extrair, fazemos Max Pooling entre cada conjunto de convoluções. Este tipo de Pooling seleciona os valores que se destacam dentro do filtro, o que vai facilitar a extração de padrões, de modo a reduzir o tamanho do output desse conjunto. Ao mesmo tempo, aumentamos o número de camadas, e o input torna-se cada vez menor.

A função de ativação a ser escolhida para esta secção foi a “Relu”. Esta função de ativação tem a vantagem de ser rápida. Após alguns testes com outras funções de ativação (Leaky Relu, GELU) verificámos que a performance do modelo não melhorava, pelo que concluímos que a escolha inicial favorecia o comportamento da  rede.

Na segunda secção (camada dense), dado que obtivemos um elevado número de parâmetros da camada de convolução, é necessária uma rede de 256 neurónios para processar as features extraídas numa expressão final. Neste caso, decidimos utilizar uma percentagem de dropout de 0.5 e Batch Normalization de forma a prevenir o overfitting.  Para a função de ativação à saída da rede, a ‘Softmax’ foi a escolha acertada pois dado que estamos perante um caso de multi-class classification, é necessária uma distribuição de probabilidades que determine a que classe a imagem pertence. Tal é feito pela função ‘Softmax’ que necessita consequentemente que a loss seja “categorical_crossentropy”. Esta função vai utilizar o output (1 hot vector) para maximizar o score dado pela rede relativamente à classe dada como positiva, ou seja, com maior probabilidade.

Modelo:

multi_class.png

Q2: Discuss and explain how you selected the best model for the multiclass classification problem, showing the relevant plots, comparing the different models you tried and evaluating the results you obtained.
Q2: Discuta e explique como seleccionou o melhor modelo para o problema de classificação multi-classe, mostrando os gráficos relevantes, comparando os diferentes modelos que experimentou e avaliando os resultados obtidos.
R2: 
A escolha do modelo final foi feita com base na accuracy para o conjunto de validação. O nosso modelo inicial tinha uma complexidade demasiado elevada e adaptava-se demasiado ao conjunto de treino, causando overfitting, pelo que decidimos simplificar. Adaptámos, em simultâneo, outros parâmetros como Learning Rate, Batch Size e Momentum. No que toca ao Learning rate, começámos por admitir que o melhor valor é 0.01 por apresentar resultados sólidos nos testes iniciais. Apesar de o modelo convergir com alguma rapidez para uma boa accuracy, notámos algumas irregularidades (spikes) no gráfico da accuracy de validação e no gráfico da loss de validação, que interpretámos como consequência da utilização do optimizador Adam (o cálculo dos gradientes poderia conduzir a este tipo de situações). De modo a resolver este problema, reduzimos o learning rate (0.001) para que houvesse uma maior estabilidade na convergência para um mínimo, o que resultou. Após  diminuirmos o valor do Learning Rate, achámos importante testar a performance do modelo face a diferentes valores de Momentum de modo a perceber se este poderia contribuir para a melhoria dos resultados. Ao efetuarmos este teste, reparámos que quanto menor o valor de Momentum, mais lenta era a convergência para um valor de accuracy aceitável, logo decidimos utilizar um momentum de 0.9.

Por último, o valor do batch size foi também crucial para aumentar a performance do nosso modelo.

BatchSizeComparison.png

ModelAccuracy50.png

ModelLoss50.png

Ao analisarmos o valor médio da accuracy de validação, reparámos que o batch size igual a 50 era o melhor valor a adotar, pois combinava um valor médio alto com um gráfico estável.



Q3: For the multilabel classification problem, explain how you adpated your previous model, what experiments you did to optimize the architecture and discuss your results. Do not forget to explain your choice of activation and loss functions and why this model differs from the previous one.
Q3: Para o problema de classificação com múltiplas etiquetas, explique como adaptou o modelo anterior, que experiências fez para optimizar a arquitectura e discuta os resultados. Não se esqueça de explicar a escolha de funções de activação e custo e porque é que este modelo difere do anterior.
R3:Para o modelo de classificação com múltiplas etiquetas, utilizamos a mesma estrutura do modelo de multi-classe, alterando apenas a função de ativação da camada final e a função de custo. A função de ativação da camada final utilizada foi a sigmóide. Esta função é a mais adequada para problemas de multi-label pois podemos usar os outputs de cada uma das 10 sigmóides da camada final para representar a probabilidade do exemplo pertencer a uma das 10 classes. Estas probabilidades são independentes entre si ao contrário do que acontecia com a função “Softmax” pelo que o output vai ser tratado por uma função de custo nova. A nova função de custo passou a ser a binary cross entropy, que permitirá penalizar as previsões de cada sigmóide conforme a sua proximidade com o que deveria ser. Um exemplo que seja de uma classe e dê valor elevado no output da sigmóide correspondente a essa classe terá pouca loss, e vice-versa. Uma vez que os resultados estavam com alguns spikes nos gráficos da accuracy, decidimos mais uma vez baixar o learning rate, algo que mais uma vez estabilizou os gráficos. Mantivemos o batch size uma vez que obtivemos bons resultados. 

ModelAccuracy50MultiLabel.png

ModelLoss50MultiLabel.png

Modelo :

multi_label.png

Q4: Explain the architecture of your best model for the semantic segmentation problem, including a description and justification of the output activation and loss functions. Also justify your choice of layers and activation functions for the hidden layers.
Q4: Explique a arquitectura do seu melhor modelo para o problema de segmentação semântica, incluindo uma descrição e justificação das funções de activação à saída da rede e função de custo. Justifique também a sua escolha de camadas e de funções de activação para as camadas escondidas.
R4:
O modelo destinado ao problema de segmentação foi resolvido mediante uma progressiva  extração dos valores-chave mais importantes ao longo da rede, assim como aconteceu com outros modelos, seguido do aproveitamento destes parâmetros para re-aumentar a dimensão da imagem.

Aqui, começamos por obter 32 features maps seguidas de uma extração das features mais importantes através da operação de Max Pooling. Após esta redução, voltamos a recriar, desta vez, 64 feature maps com posterior MaxPooling. Após esta fase de encoding, recriamos o tamanho da imagem com base no que obtivemos do recebido como input, pelo que fazemos UpSamplings há medida que fazemos novas convoluções. Aqui, criamos 128 camadas de convoluções de modo a computarmos um maior número de features com base nos dados que codificamos. Por fim, é criado um último feature map que contém os valores de output e que vai refletir a segmentação final. Os resultados obtidos foram desde já bastante positivos. No entanto, ao adicionarmos nós de Dropout, verificámos que os resultados melhoraram bastante. Como função de ativação, decidimos utilizar a função de Relu.  A computação desta função é bastante mais rápida e fornece resultados ligeiramente melhores do que outras funções (GELU, Leaky Relu). Aqui, como função de loss utilizámos a de binary cross entropy pois a computação dos erros é independente para os diferentes outputs das redes, o que facilita o seu respetivo cálculo para este caso de segmentação. Para que este tipo de loss seja computado é necessário que a função de ativação seja a Sigmóide, como foi verificado também no modelo de Multi-label.

Modelo:
segmentation_model.png

Q5: Discuss and explain how you selected the best model for the semantic segmentation problem, showing the relevant plots, comparing the different models you tried and evaluating the results you obtained. Use the auxiliary functions provided to show the correspondence between your predicted segmentation masks and the masks provided in the test set.
Q5: Discuta e explique como seleccionou o melhor modelo para o problema de segmentação semântica, mostrando os gráficos relevantes, comparando os diferentes modelos que experimentou e avaliando os resultados obtidos. Use as funções auxiliares fornecidas para mostrar a correspondência entre as máscaras de segmentação previstas e as máscaras no conjunto de teste.
R5: 
A escolha do modelo final foi feita com base nos resultados dos métodos auxiliares compare_masks. O learning rate de 0.01 obteve bons resultados, pelo que o decidimos manter. O mesmo aconteceu para o valor do batch size. As seguintes imagens demonstram a performance destes parâmetros, relativamente à accuracy e à loss.

ModelAccuracy.png

ModelLoss.png

O resultado dos métodos auxiliares compare_masks e overlay_masks também demonstram a boa capacidade do modelo para distinguir os pokémons do resto da imagem, como se vê pelas seguintes imagens

CompareMasks.png

OverlayMaks.png

Com o modelo construído, verificámos que a criação de um maior número de feature maps numa fase de reconstrução da imagem é positivo para o aumento da accuracy, o que induz que a extração de features através de convoluções e poolings feitos faz sentido e traduz alguma complexidade em bons resultados.



Q6: (Optional) Discuss the impact on training and overfitting for the two classification problems when using available networks pretrained on ImageNet (e.g. EfficientNetB0, MobileNetV2 or others). Explain how you used these networks and discuss the effect they had relative to your models.
Q6: (Opcional) Discuta o impacto no treino e sobreajustamento nos dois problemas de classificação se usar redes pré-treinadas no dataset ImageNet (e.g. EfficientNetB0, MobileNetV2 or others). Explique como usou estas redes e discuta o efeito que tiveram nos seus modelos.
R6:



